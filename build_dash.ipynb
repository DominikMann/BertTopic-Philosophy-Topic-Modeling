{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f836f8-0771-43c5-b0b5-f32d2708e0fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install and load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26119f35-3e87-4dea-9b47-eebef4dfb3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nremove docstring to install required packages\\n\\n!pip install sentence_transformers\\n!conda install -c conda-forge hdbscan -y\\n!pip install bertopic\\n!pip install cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\\n!pip install cuml-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\\n!pip install cugraph-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\\n!pip uninstall cupy-cuda115 -y\\n!pip uninstall cupy-cuda11x -y\\n!pip install cupy-cuda11x -f https://pip.cupy.dev/aarch64\\n!pip install ipywidgets --upgrade\\n!pip install dash\\n!pip install --upgrade ipykernel\\n!pip install jupyterlab-dash\\n!pip install dash_bootstrap_components\\n!pip install wordcloud\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "remove docstring to install required packages\n",
    "\n",
    "!pip install sentence_transformers\n",
    "!conda install -c conda-forge hdbscan -y\n",
    "!pip install bertopic\n",
    "!pip install cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n",
    "!pip install cuml-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n",
    "!pip install cugraph-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n",
    "!pip uninstall cupy-cuda115 -y\n",
    "!pip uninstall cupy-cuda11x -y\n",
    "!pip install cupy-cuda11x -f https://pip.cupy.dev/aarch64\n",
    "!pip install ipywidgets --upgrade\n",
    "!pip install dash\n",
    "!pip install --upgrade ipykernel\n",
    "!pip install jupyterlab-dash\n",
    "!pip install dash_bootstrap_components\n",
    "!pip install wordcloud\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9d94fa-e3e9-4cb3-829c-f5444574dfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from bertopic import BERTopic\n",
    "from bertopic.backend._utils import select_backend\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import dash\n",
    "from dash import html\n",
    "import dash_core_components as dcc\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import Dash, dash_table\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc7532-2807-4d6a-b736-e0fa9bb8f296",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1f99e9-a26e-4538-a361-79c29e8135d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read preprocessed data\n",
    "df = pd.read_csv('processed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41fc4cbb-9c5e-42d8-904d-9a842f108cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe some important key data from df to integrate into data table later\n",
    "docs = df.Abstract.tolist()\n",
    "title = df.Title.tolist()\n",
    "year = df.Year.tolist()\n",
    "journal = df.Journal.tolist()\n",
    "author = df.Name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a689921-501c-466c-8f21-8f9ce0321f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a custom vectorizer class\n",
    "class CustomVectorizer(CountVectorizer): \n",
    "       \n",
    "    stop_grams = []    \n",
    "    \n",
    "    def __init__(self, stop_grams = [], **opts):\n",
    "        self.stop_grams = stop_grams\n",
    "        super().__init__(**opts)\n",
    "    \n",
    "    def remove_ngrams(self, doc):\n",
    "        for stop_gram in self.stop_grams:\n",
    "            doc = doc.replace(stop_gram, \"\")\n",
    "        return doc\n",
    "    \n",
    "    # overwrite the build_analyzer method, allowing one to\n",
    "    # create a custom analyzer for the vectorizer\n",
    "    def build_analyzer(self):\n",
    "        \n",
    "        # load stop words using CountVectorizer's built in method\n",
    "        stop_words = list(self.get_stop_words())\n",
    "        \n",
    "        preprocessor = self.build_preprocessor()\n",
    "        tokenizer = self.build_tokenizer()\n",
    "        remove_ngrams = self.remove_ngrams\n",
    "        \n",
    "        \n",
    "        # create the analyzer that will be returned by this method\n",
    "        def analyser(doc):\n",
    "                \n",
    "            # apply the preprocessing and tokenzation steps\n",
    "            doc_clean = preprocessor(doc.lower())\n",
    "            \n",
    "            # remove phrase stopwords\n",
    "            doc_clean = remove_ngrams(doc)\n",
    "            \n",
    "            # tokenize using default tokenizer\n",
    "            tokens = tokenizer(doc_clean)            \n",
    "            \n",
    "            # use CountVectorizer's _word_ngrams built in method\n",
    "            # to remove stop words and extract n-grams\n",
    "            return(self._word_ngrams(tokens, stop_words))\n",
    "        \n",
    "        return(analyser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca9f14a-b312-448c-9a69-efda13d8faed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load embeddings and model\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "model = select_backend(embedding_model)\n",
    "model_bert = BERTopic.load(\"final_model\", embedding_model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ca9576-b77f-4619-87f4-22b0dbec5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the topics\n",
    "topics = model_bert.get_topics()\n",
    "\n",
    "# get the topic labels\n",
    "labels = model_bert.custom_labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765cfdca-b23c-40a7-835a-b8307c50571f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc727ef-e668-49cb-9767-4f443db66685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics over time\n",
    "topics_over_time = pd.read_csv('tot_both.csv')\n",
    "tot = model_bert.visualize_topics_over_time(topics_over_time, custom_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f97f1d5b-0c3b-4293-94c6-b0fc8f7f3bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization of documents with titles instead of abstract in the plot when hovering over\n",
    "vis_docs = model_bert.visualize_documents(title, embeddings = embeddings, width = 1250, custom_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19db1ac2-9026-4fa4-b9ea-c9fa62bab1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Similarity matrix\n",
    "vis_heatmap = model_bert.visualize_heatmap(width = 1250, custom_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c3e598-a005-492f-8438-411c2582bf40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Topics per Journal\n",
    "classes = list(df[\"Journal\"])\n",
    "topics_per_class = pd.read_csv('tpc.csv')\n",
    "tpc = model_bert.visualize_topics_per_class(topics_per_class, top_n_topics = 66, width = 1250, custom_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5507c8f6-0832-437a-b004-611a7c434d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topicname</th>\n",
       "      <th>Document</th>\n",
       "      <th>Top 15 words</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14038</th>\n",
       "      <td>We Don’T Know We Don’T Know: Asserting Ignorance.</td>\n",
       "      <td>2019</td>\n",
       "      <td>Massimiliano Carrara</td>\n",
       "      <td>Synthese</td>\n",
       "      <td>-1</td>\n",
       "      <td>Stop words</td>\n",
       "      <td>The pragmatic logic of assertions shows a conn...</td>\n",
       "      <td>paper - one - argument - knowledge - show - ep...</td>\n",
       "      <td>0.711914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>Requirements of intention in light of belief.</td>\n",
       "      <td>2020</td>\n",
       "      <td>Carlos Núñez</td>\n",
       "      <td>Philosophical Studies</td>\n",
       "      <td>-1</td>\n",
       "      <td>Stop words</td>\n",
       "      <td>Much work in the philosophy of action in the l...</td>\n",
       "      <td>paper - one - argument - knowledge - show - ep...</td>\n",
       "      <td>0.425701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>Perdurantism, Fecklessness and the Veil of Ign...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Michael Tze-Sung Longenecker</td>\n",
       "      <td>Philosophical Studies</td>\n",
       "      <td>-1</td>\n",
       "      <td>Stop words</td>\n",
       "      <td>There has been a growing charge that perdurant...</td>\n",
       "      <td>paper - one - argument - knowledge - show - ep...</td>\n",
       "      <td>0.420331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4645</th>\n",
       "      <td>We talk to people, not contexts.</td>\n",
       "      <td>2020</td>\n",
       "      <td>Daniel W. Harris</td>\n",
       "      <td>Philosophical Studies</td>\n",
       "      <td>-1</td>\n",
       "      <td>Stop words</td>\n",
       "      <td>According to a popular family of theories, ass...</td>\n",
       "      <td>paper - one - argument - knowledge - show - ep...</td>\n",
       "      <td>0.526087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4636</th>\n",
       "      <td>“Ontological Commitment and Ontological Commit...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jared Warren</td>\n",
       "      <td>Philosophical Studies</td>\n",
       "      <td>-1</td>\n",
       "      <td>Stop words</td>\n",
       "      <td>The standard account of ontological commitment...</td>\n",
       "      <td>paper - one - argument - knowledge - show - ep...</td>\n",
       "      <td>0.837428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>The Analytic-Synthetic Distinction and the Cla...</td>\n",
       "      <td>2010</td>\n",
       "      <td>Willem R. De Jong</td>\n",
       "      <td>Synthese</td>\n",
       "      <td>88</td>\n",
       "      <td>Quine</td>\n",
       "      <td>This paper concentrates on some aspects of the...</td>\n",
       "      <td>Quine - analyticity - analytic - Two Dogmas - ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10088</th>\n",
       "      <td>Quine, Analyticity and Philosophy of Mathematics.</td>\n",
       "      <td>2004</td>\n",
       "      <td>John P. Burgess</td>\n",
       "      <td>Philosophical Quarterly</td>\n",
       "      <td>88</td>\n",
       "      <td>Quine</td>\n",
       "      <td>Quine correctly argues that Carnaps distinctio...</td>\n",
       "      <td>Quine - analyticity - analytic - Two Dogmas - ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14691</th>\n",
       "      <td>Logic in Analytic Philosophy: A Quantitative A...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Guido Bonino</td>\n",
       "      <td>Synthese</td>\n",
       "      <td>88</td>\n",
       "      <td>Quine</td>\n",
       "      <td>Using quantitative methods, we investigate the...</td>\n",
       "      <td>Quine - analyticity - analytic - Two Dogmas - ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>On Quine on Carnap on Ontology.</td>\n",
       "      <td>2001</td>\n",
       "      <td>Marc Alspector-Kelly</td>\n",
       "      <td>Philosophical Studies</td>\n",
       "      <td>88</td>\n",
       "      <td>Quine</td>\n",
       "      <td>W. V. Quine assumed that in Empiricism, Semant...</td>\n",
       "      <td>Quine - analyticity - analytic - Two Dogmas - ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2068</th>\n",
       "      <td>Whither Constructive Empiricism?</td>\n",
       "      <td>2001</td>\n",
       "      <td>Paul Teller</td>\n",
       "      <td>Philosophical Studies</td>\n",
       "      <td>88</td>\n",
       "      <td>Quine</td>\n",
       "      <td>In this paper I will set out my understanding ...</td>\n",
       "      <td>Quine - analyticity - analytic - Two Dogmas - ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16171 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  Year  \\\n",
       "14038  We Don’T Know We Don’T Know: Asserting Ignorance.  2019   \n",
       "4652       Requirements of intention in light of belief.  2020   \n",
       "4648   Perdurantism, Fecklessness and the Veil of Ign...  2020   \n",
       "4645                    We talk to people, not contexts.  2020   \n",
       "4636   “Ontological Commitment and Ontological Commit...  2020   \n",
       "...                                                  ...   ...   \n",
       "11979  The Analytic-Synthetic Distinction and the Cla...  2010   \n",
       "10088  Quine, Analyticity and Philosophy of Mathematics.  2004   \n",
       "14691  Logic in Analytic Philosophy: A Quantitative A...  2020   \n",
       "2110                     On Quine on Carnap on Ontology.  2001   \n",
       "2068                    Whither Constructive Empiricism?  2001   \n",
       "\n",
       "                             Author                  Journal  Topic  \\\n",
       "14038          Massimiliano Carrara                 Synthese     -1   \n",
       "4652                   Carlos Núñez    Philosophical Studies     -1   \n",
       "4648   Michael Tze-Sung Longenecker    Philosophical Studies     -1   \n",
       "4645               Daniel W. Harris    Philosophical Studies     -1   \n",
       "4636                   Jared Warren    Philosophical Studies     -1   \n",
       "...                             ...                      ...    ...   \n",
       "11979             Willem R. De Jong                 Synthese     88   \n",
       "10088               John P. Burgess  Philosophical Quarterly     88   \n",
       "14691                  Guido Bonino                 Synthese     88   \n",
       "2110           Marc Alspector-Kelly    Philosophical Studies     88   \n",
       "2068                    Paul Teller    Philosophical Studies     88   \n",
       "\n",
       "        Topicname                                           Document  \\\n",
       "14038  Stop words  The pragmatic logic of assertions shows a conn...   \n",
       "4652   Stop words  Much work in the philosophy of action in the l...   \n",
       "4648   Stop words  There has been a growing charge that perdurant...   \n",
       "4645   Stop words  According to a popular family of theories, ass...   \n",
       "4636   Stop words  The standard account of ontological commitment...   \n",
       "...           ...                                                ...   \n",
       "11979       Quine  This paper concentrates on some aspects of the...   \n",
       "10088       Quine  Quine correctly argues that Carnaps distinctio...   \n",
       "14691       Quine  Using quantitative methods, we investigate the...   \n",
       "2110        Quine  W. V. Quine assumed that in Empiricism, Semant...   \n",
       "2068        Quine  In this paper I will set out my understanding ...   \n",
       "\n",
       "                                            Top 15 words  Probability  \n",
       "14038  paper - one - argument - knowledge - show - ep...     0.711914  \n",
       "4652   paper - one - argument - knowledge - show - ep...     0.425701  \n",
       "4648   paper - one - argument - knowledge - show - ep...     0.420331  \n",
       "4645   paper - one - argument - knowledge - show - ep...     0.526087  \n",
       "4636   paper - one - argument - knowledge - show - ep...     0.837428  \n",
       "...                                                  ...          ...  \n",
       "11979  Quine - analyticity - analytic - Two Dogmas - ...     1.000000  \n",
       "10088  Quine - analyticity - analytic - Two Dogmas - ...     1.000000  \n",
       "14691  Quine - analyticity - analytic - Two Dogmas - ...     1.000000  \n",
       "2110   Quine - analyticity - analytic - Two Dogmas - ...     1.000000  \n",
       "2068   Quine - analyticity - analytic - Two Dogmas - ...     1.000000  \n",
       "\n",
       "[16171 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Safe Info about Documents and Topics in a suitable dataframe\n",
    "docs_info = model_bert.get_document_info(docs)\n",
    "docs_info['Title'] = title\n",
    "docs_info['Year'] = year\n",
    "docs_info['Journal'] = journal\n",
    "docs_info['Author'] = author\n",
    "docs_info.drop('Representative_document', axis = 1)\n",
    "for i in range(len(topics)):\n",
    "    docs_info['Name'][docs_info.Topic == i-1] = labels[i]\n",
    "docs_info.rename(columns={'Name':'Topicname'}, inplace=True)\n",
    "docs_info.rename(columns={'Top_n_words':'Top 15 words'}, inplace=True)\n",
    "\n",
    "docs_info = docs_info[['Title', 'Year', 'Author', 'Journal', 'Topic', 'Topicname', 'Document', 'Top 15 words','Probability']]\n",
    "docs_info.sort_values(by='Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd434db7-950f-4f1c-b360-aeda97fb6924",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68329ff-2d1a-417f-889a-cbfabd7abeae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://localhost:8041/\n",
      "\n",
      "Dash is running on http://localhost:8041/\n",
      "\n",
      "Dash is running on http://localhost:8041/\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "# build dashboard\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "'''\n",
    "TODO:\n",
    "- adjust font for markdown elements\n",
    "- add elements see below\n",
    "- dropdown menus\n",
    "- remaining vis. descriptions\n",
    "\n",
    "'''\n",
    "\n",
    "intro_dash = '''\n",
    "This is a Plotly dashboard built by master's students of Applied Statistics at the Georg August University \n",
    "Göttingen. We developed a topic model with the help of the BERTopic package by Martin Grootendorst.\n",
    "Our objective is to give philosophers the option to browse through visualizations of the Topic Model,\n",
    "which approximates topics for abstracts of philosophical papers published since 2000 in \n",
    "the top 11 philosophical journals (see data set for names of papers).\n",
    "Ultimately, the goal is to give researchers some direction for future publications.\n",
    "\n",
    "The labeling of Topics was performed manually in cooperation with our project partner, \n",
    "Dr. Tobias Störzinger. All other results are based on the model developed with BERTopic. \n",
    "To review model specifications, view this project on [GitHub](https://github.com/DominikMann/BertTopic-Philosophy-Topic-Modeling), and for a deeper understanding, \n",
    "read our paper on this project (URL).\n",
    "\n",
    "Note that this model cannot perfectly resemble the true underlying topic structure, \n",
    "and the methods used produce outliers that result in a trash-category (Topic 'Stop words'/ -1).\n",
    "These topics and papers belonging to them cannot be meaningfully interpreted. \n",
    "Furthermore, the underlying publications used to build the model are not evenly distributed \n",
    "over journals and years; therefore, interpretations of representativeness should be made carefully. \n",
    "Also note that all papers which did not provide an abstract were not considered.\n",
    "\n",
    "In this dashboard you can browse through topics created by the model via\n",
    "- a Data Table \n",
    "- a Wordcloud\n",
    "- a Graph displaying Topics per Journal\n",
    "- a Graph displaying Topics over Time \n",
    "- a dimensionality-reduced cluster/ distance map\n",
    "- a Similarity Matrix\n",
    "- a Similarity search for Topics similar to your own search term\n",
    "'''\n",
    "# hier müssen noch die richtigen Links zum Paper rein!\n",
    "# Probabilities sind noch falsch erklärt!\n",
    "\n",
    "text_table = '''\n",
    "This data table displays the assignment of the generated topics to the abstracts. \n",
    "For the whole picture some key data (Author, Title, Year, Journal) about the publishments is displayed as well. You can also view\n",
    "the top 15 words representing one topic and the probabilities of each topic in each abstract.\n",
    "Hover over the columns which are not fully shown (abstracts) to read the full text.\n",
    "You can filter the data using the dropdown below the datatable. \n",
    "Selecting multiple options in multiple categories is possible.\n",
    "You can also use the filtering option below the header. Here you must use operators to view results.\n",
    "All possible operators are listed [here](https://dash.plotly.com/datatable/filtering).\n",
    "'''\n",
    "\n",
    "text_wc = '''\n",
    "This is a Word Cloud generated for each topic. You can view each topic with its top 15 word representations.\n",
    "The more representative a word is for a topic, the bigger it will be displayed in the Word Cloud.\n",
    "Use the dropdown menu to select a topic for which you want the Word Cloud to be displayed.\n",
    "'''\n",
    "\n",
    "text_tpc = '''\n",
    "This plot displays the number of abstracts per journal for each topic. \n",
    "You may select topics from the list of topics on the right to limit the number of topics shown. \n",
    "Clicking once on a topic will hide it. If you double-click on one or multiple topcis, only these are shown.\n",
    "Hovering over the plot, you can see how the words that define a topic differ over Journals. \n",
    "Use the magnifying-glass tool to select a specific area of the graph, e.g. just one Journal.\n",
    "'''\n",
    "\n",
    "text_tot = '''\n",
    "This plot displays the number of documents per topic (frequency) over the years.\n",
    "You may select topics from the list of topics on the right to limit the number of topics shown. \n",
    "Clicking once on a topic will hide it. If you double-click on one or multiple topcis, only these are shown.\n",
    "Hovering over the plot, you can see how the words that define a topic differ over time.\n",
    "'''\n",
    "\n",
    "text_vis_docs = '''\n",
    "Each of the dots in the plot represents one document. Their similarity is shown by the distance towards each other. \n",
    "As the distance increases, they are less similar. Due to the underlying algorithm that reduces their complex dimensionality into these displayed \n",
    "two dimensions, their global structure might not be displayed perfectly.\n",
    "The clusters colored in distinct colors are representing the topics. \n",
    "You may click on the topics from the list of topics on the right to only show selected topics. Clicking once on a topic will hide it. \n",
    "If you double-click on one or multiple topcis, only these are shown.\n",
    "You can also zoom in and out of the map for a broader overview or for viewing a specific area.\n",
    "'''\n",
    "\n",
    "text_vis_heatmap = '''\n",
    "This matrix shows the similarity (measured as cosine distance) of each topic to all other topics. The higher the similarity score, the more\n",
    "similar the topcis are.\n",
    "By default a reduced number of topics is shown. Zoom into the plot using the toolbar to show a higher resolution of topics.\n",
    "'''\n",
    "\n",
    "text_simsearch = '''\n",
    "This is an interactive search, which enables you to find topics that are similar to a word chosen by you. \n",
    "Select a number of similar topics that should be displayed. Type in a search term and press enter to find topics that are similar.\n",
    "You are given the topic, its top 15 words and a similarity score. You can use the score to compare which topic is most similar to your search term.\n",
    "The higher the score the more closely related is the search term to the topic.\n",
    "'''\n",
    "\n",
    "# Define function for generatig word cloud\n",
    "def plot_wordcloud(topic):\n",
    "    text = {word: value for word, value in model_bert.get_topic(topic)}\n",
    "    wc = WordCloud(background_color=\"white\", max_words=1000)\n",
    "    wc.generate_from_frequencies(text)\n",
    "    return wc.to_image()\n",
    "\n",
    "# Define function for similarity search\n",
    "def get_similar(word, top_n = 3, model_bert=model_bert):\n",
    "    similar_topics, similarity = model_bert.find_topics(word, top_n=top_n)\n",
    "    sim_df = pd.DataFrame(columns=['Topic Number', 'Topic Name', 'Topic Words', 'Similarity Score'])\n",
    "    sim_df.index.name = 'Topic Number'\n",
    "\n",
    "    for i in range(len(similar_topics)):\n",
    "        top_num = similar_topics[i]\n",
    "        tops = model_bert.get_topic(top_num)\n",
    "        names = labels[top_num + 1]\n",
    "        top_words = list(item[0] for item in tops)\n",
    "        top_words = \", \".join(top_words)\n",
    "        sim_score = similarity[i]\n",
    "\n",
    "        topic_list = [top_num, names, top_words, sim_score]\n",
    "\n",
    "        sim_df = sim_df.append(pd.Series(topic_list, index=sim_df.columns, name=top_num))\n",
    "        \n",
    "    return sim_df\n",
    "\n",
    "\n",
    "app.layout = html.Div( children=[\n",
    "    \n",
    "    # Welcome\n",
    "    html.H1('Philosophical Topic Modellig – Visualizations', \n",
    "            style={'textAlign':'center', 'font-family':'sans-serif', 'font-size':30}),\n",
    "    \n",
    "    dcc.Markdown(children = intro_dash, style = {'display': 'inline-block',\n",
    "                                                   'width': '1200px',\n",
    "                                                   'padding': '10px 20px',\n",
    "                                                   'text-align': 'left',\n",
    "                                                   'vertical-align': 'top',\n",
    "                                                   'font-family':'sans-serif',\n",
    "                                                   'font-size':12\n",
    "                                                }),\n",
    "    # DataTable\n",
    "    dbc.Container([\n",
    "        html.H2('Data Table', style={'textAlign':'center','font-family':'sans-serif', 'font-size':25}),\n",
    "        dbc.Label('Show number of rows', style= {'font-family':'sans-serif','font-size':12}),\n",
    "        row_drop := dcc.Dropdown(value = 10, clearable=False, style={'width':'35%', 'font-family':'sans-serif','font-size':12},\n",
    "                 options=[10, 25, 50, 100, 200]),\n",
    "\n",
    "        docs_info_table := dash_table.DataTable(\n",
    "                columns = [ {'name': i, 'id': i, 'deletable': True} for i in docs_info.columns\n",
    "                    ],\n",
    "                data = docs_info.to_dict('records'),\n",
    "                filter_action = 'native',\n",
    "                page_size = 10,\n",
    "\n",
    "                style_data={\n",
    "                    'width': '150px', 'minWidth': '150px', 'maxWidth': '150px',\n",
    "                    'overflow': 'hidden',\n",
    "                    'textOverflow': 'ellipsis',},\n",
    "                style_header={\n",
    "                    'font-family':'sans-serif'},\n",
    "                style_cell={'font-family':'sans-serif',\n",
    "                            'font-size':12},\n",
    "                style_as_list_view=True,\n",
    "        ),\n",
    "        \n",
    "\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.Label('Filter the data', style= {'font-family':'sans-serif','font-size':12}),\n",
    "                year_drop := dcc.Dropdown([x for x in sorted(docs_info.Year.unique())], \n",
    "                                          multi=True, \n",
    "                                          placeholder=\"select Years\", \n",
    "                                          style= {'font-family':'sans-serif','font-size':12})\n",
    "            ], width=3),\n",
    "            dbc.Col([\n",
    "                journal_drop := dcc.Dropdown([x for x in sorted(docs_info.Journal.unique())],\n",
    "                                             multi=True,\n",
    "                                             placeholder=\"select Journals\",\n",
    "                                             style= {'font-family':'sans-serif','font-size':12})\n",
    "            ], width=3),\n",
    "            dbc.Col([\n",
    "                topic_drop := dcc.Dropdown([x for x in sorted(docs_info.Topic.unique())],\n",
    "                                           multi=True,\n",
    "                                           placeholder=\"select Topic Numbers\",\n",
    "                                           style= {'font-family':'sans-serif','font-size':12})\n",
    "            ], width=3),\n",
    "            dbc.Col([\n",
    "                name_drop := dcc.Dropdown([x for x in sorted(docs_info.Topicname.unique())],\n",
    "                                           multi=True,\n",
    "                                           placeholder=\"select Topics by Name\",\n",
    "                                           style= {'font-family':'sans-serif','font-size':12})\n",
    "            ], width=3),\n",
    "        ]),\n",
    "        \n",
    "        dcc.Markdown(children = text_table, style = {'display': 'inline-block',\n",
    "                                                     'width': '1200px',\n",
    "                                                     'padding': '10px 20px',\n",
    "                                                     'text-align': 'left',\n",
    "                                                     'vertical-align': 'top',\n",
    "                                                     'font-family':'sans-serif',\n",
    "                                                     'font-size':12,\n",
    "                                                     'marginBottom': 100,\n",
    "                                                     'marginTop': 0\n",
    "                                                    }),\n",
    "\n",
    "    ]),\n",
    "    \n",
    "    \n",
    "    # Word cloud\n",
    "    html.Div([\n",
    "        html.H2('Word Cloud', style={'textAlign':'center', 'font-family':'sans-serif', 'font-size':25}),\n",
    "        dbc.Label('Select a topic to generate its Word Cloud', style= {'font-family':'sans-serif','font-size':12}),\n",
    "        html.Br(),\n",
    "        dcc.Dropdown(id='topicwc_drop',\n",
    "                     options=[{'label': f\"Topic '{labels[i+1]}'\", 'value': i} for i in topics.keys()],\n",
    "                     value=0,\n",
    "                     style = {'display': 'inline-block',\n",
    "                              'width':'35%',\n",
    "                              'padding': '10px 20px',\n",
    "                              'text-align': 'left',\n",
    "                              'vertical-align': 'top',\n",
    "                              'font-family':'sans-serif',\n",
    "                              'font-size':12}),\n",
    "        html.Br(),\n",
    "                           \n",
    "        html.Img(id=\"image_wc\", style = {'display': 'inline-block',\n",
    "                                        'width': '500px',\n",
    "                                        'padding': '10px 20px',\n",
    "                                        'text-align': 'center',\n",
    "                                        'vertical-align': 'top'}),\n",
    "        \n",
    "        dcc.Markdown(children = text_wc, style = {'display': 'inline-block',\n",
    "                                                     'width': '1200px',\n",
    "                                                     'padding': '10px 20px',\n",
    "                                                     'text-align': 'left',\n",
    "                                                     'vertical-align': 'top',\n",
    "                                                     'font-family':'sans-serif',\n",
    "                                                     'font-size':12,\n",
    "                                                     'marginBottom': 100,\n",
    "                                                     'marginTop': 0\n",
    "                                                    }),\n",
    "    ]),\n",
    "    \n",
    "    \n",
    "    # Topics per Journal\n",
    "    html.Div(\n",
    "        children = [\n",
    "            dcc.Graph(id = \"tpc\", figure = tpc, style = {'display': 'inline-block'}\n",
    "                     ),\n",
    "            dcc.Markdown(children = text_tpc, style = {'display': 'inline-block',\n",
    "                                                       'width': '1200px',\n",
    "                                                       'padding': '10px 20px',\n",
    "                                                       'text-align': 'left',\n",
    "                                                       'vertical-align': 'top',\n",
    "                                                       'font-family':'sans-serif',\n",
    "                                                       'font-size':12,\n",
    "                                                       'marginBottom': 100,\n",
    "                                                       'marginTop': -25\n",
    "                                                      }),\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    \n",
    "    # Topics over Time\n",
    "    dbc.Container([\n",
    "        dcc.Graph(id = \"tot\", figure = tot, style = {'display': 'inline-block'}\n",
    "                     ),\n",
    "        dcc.Markdown(children = text_tot, style = {'display': 'inline-block',\n",
    "                                                   'width': '1200px',\n",
    "                                                   'padding': '10px 20px',\n",
    "                                                   'text-align': 'left',\n",
    "                                                   'vertical-align': 'top',\n",
    "                                                   'font-family':'sans-serif',\n",
    "                                                   'font-size':12,\n",
    "                                                   'marginBottom': 100,\n",
    "                                                   'marginTop': -25\n",
    "                                                  }),\n",
    "        \n",
    "        \n",
    "    ]),\n",
    "\n",
    "    # Cluster Map\n",
    "    html.Div(\n",
    "        children=[\n",
    "            dcc.Graph(id = \"vis_docs\", figure = vis_docs, style = {'display': 'inline-block'}\n",
    "                     ),\n",
    "            dcc.Markdown(children = text_vis_docs, style = {'display': 'inline-block',\n",
    "                                                            'width': '1200px',\n",
    "                                                            'padding': '10px 20px',\n",
    "                                                            'text-align': 'left',\n",
    "                                                            'vertical-align': 'top',\n",
    "                                                            'font-family':'sans-serif',\n",
    "                                                            'font-size':12,\n",
    "                                                            'marginBottom': 100,\n",
    "                                                            'marginTop': -25\n",
    "                                                           }),\n",
    "        ]\n",
    "    ),\n",
    " \n",
    "    # Similarity Matrix\n",
    "    html.Div(\n",
    "        children=[\n",
    "            dcc.Graph(id = \"vis_heatmap\", figure = vis_heatmap, style = {'display': 'inline-block'}\n",
    "                     ),\n",
    "            dcc.Markdown(children = text_vis_heatmap, style = {'display': 'inline-block',\n",
    "                                                               'width': '1200px',\n",
    "                                                               'padding': '10px 20px',\n",
    "                                                               'text-align': 'left',\n",
    "                                                               'vertical-align': 'top',\n",
    "                                                               'font-family':'sans-serif',\n",
    "                                                               'font-size':12,\n",
    "                                                               'marginBottom': 100,\n",
    "                                                               'marginTop': -25\n",
    "                                                              }),\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    \n",
    "    # Similarity search\n",
    "    html.Div(\n",
    "        children=[\n",
    "            html.H2('Similarity Search', style={'textAlign':'center', 'font-family':'sans-serif', 'font-size':25}),\n",
    "            dbc.Label('Select the number of similar topics shown', style= {'font-family':'sans-serif','font-size':12}),\n",
    "            html.Br(),\n",
    "            dcc.Dropdown(id = 'top_n_drop', \n",
    "                         options=[{'label': f'{i}', 'value': i} for i in range(1, 11)],\n",
    "                         value=3, style = {'display': 'inline-block',\n",
    "                                           'width':'35%',\n",
    "                                           'padding': '10px 20px',\n",
    "                                           'text-align': 'left',\n",
    "                                           'vertical-align': 'top',\n",
    "                                           'font-family':'sans-serif',\n",
    "                                           'font-size':12}),\n",
    "            \n",
    "            html.Br(),\n",
    "            dbc.Label('Enter a word you want to search for:', style= {'font-family':'sans-serif', 'font-size':12,}),\n",
    "            html.Div([\"Input: \",\n",
    "                      dcc.Input(id='word_input', type='text', debounce=True, placeholder='word to search for',\n",
    "                                spellCheck=True)\n",
    "                     ]),\n",
    "            html.Br(),\n",
    "            html.Div(id='word_output', style= {'font-family':'sans-serif', 'font-size':12, 'marginTop': -20}),\n",
    "            dcc.Markdown(children = text_simsearch, style = {'display': 'inline-block',\n",
    "                                                            'width': '1200px',\n",
    "                                                            'padding': '10px 20px',\n",
    "                                                            'text-align': 'left',\n",
    "                                                            'vertical-align': 'top',\n",
    "                                                            'font-family':'sans-serif',\n",
    "                                                            'font-size':12,\n",
    "                                                            'marginBottom': 100,\n",
    "                                                            'marginTop': -15\n",
    "                                                           }),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "]\n",
    "                     )\n",
    "\n",
    "@app.callback(\n",
    "    Output(docs_info_table, 'data'),\n",
    "    Output(docs_info_table, 'page_size'),\n",
    "    Input(year_drop, 'value'),\n",
    "    Input(journal_drop, 'value'),\n",
    "    Input(topic_drop, 'value'),\n",
    "    Input(name_drop, 'value'),\n",
    "    Input(row_drop, 'value')\n",
    ")\n",
    "\n",
    "def update_dropdown_options(year_v, journal_v, topic_v, name_v, row_v):\n",
    "    dff = docs_info.copy()\n",
    "\n",
    "    if year_v:\n",
    "        dff = dff[dff.Year.isin(year_v)]\n",
    "        \n",
    "    if journal_v:\n",
    "        dff = dff[dff.Journal.isin(journal_v)]\n",
    "        \n",
    "    if topic_v:\n",
    "        dff = dff[dff.Topic.isin(topic_v)]\n",
    "    \n",
    "    if name_v:\n",
    "        dff = dff[dff.Topicname.isin(name_v)]\n",
    "        \n",
    "    return dff.to_dict('records'), row_v\n",
    "\n",
    "@app.callback(\n",
    "    Output('image_wc', 'src'),\n",
    "    Input('image_wc', 'id'),\n",
    "    Input('topicwc_drop', 'value'))    \n",
    "\n",
    "def make_image(b, topicwc_drop):\n",
    "    img = BytesIO()\n",
    "    plot_wordcloud(topicwc_drop).save(img, format='PNG')\n",
    "    \n",
    "    return 'data:image/png;base64,{}'.format(base64.b64encode(img.getvalue()).decode())\n",
    "\n",
    "@app.callback(\n",
    "    Output('word_output', 'children'),\n",
    "    Input('word_input', 'value'),\n",
    "    Input ('top_n_drop', 'value')\n",
    ")\n",
    "\n",
    "def func_sim(word_input, top_n_drop):\n",
    "    if word_input:\n",
    "        df_sim = get_similar(word_input, top_n_drop)\n",
    "        data_sim = df_sim.to_dict('records')\n",
    "        columns_sim =  [{\"name\": i, \"id\": i,} for i in (df_sim.columns)]\n",
    "        return dash_table.DataTable(data=data_sim, columns=columns_sim,\n",
    "                            style_data={\n",
    "                                'width': '150px', 'minWidth': '150px', 'maxWidth': '700px',\n",
    "                                'overflow': 'hidden',\n",
    "                                'textOverflow': 'ellipsis',\n",
    "                                'border':'0.5px solid'},\n",
    "                            style_header={\n",
    "                                'font-family':'sans-serif',\n",
    "                                'border':'0.5px solid'},\n",
    "                            style_cell={'font-family':'sans-serif',\n",
    "                                        'font-size':12,\n",
    "                                        'textAlign':'left'},\n",
    "                            style_as_list_view=True,\n",
    "                           )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(host=\"localhost\",port=8041, debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c288f-a362-4beb-a5ba-b335a2173c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
